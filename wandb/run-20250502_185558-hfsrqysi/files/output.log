🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.57epoch/s, batch_max_reward=606, best_reward=654, loss=0.922]


🏁 Training finished
✨ Best reward: 653.87109375
🧩 Best sequence: [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]
-------------
653.8710937000001
653.8711
445.99999995
446.0
-------------
[1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 0 0 0 1]
[1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]
-------------
[2.8242188  0.         0.         0.         6.76953125 8.7421875
 9.9453125  8.8125     6.9296875  6.94921875 8.4609375  9.359375
 9.859375   8.8984375  8.03125    8.2109375  9.703125   9.359375
 8.3984375  6.28515625]
[89. 17. 91. 17. 44. 80. 82. 67. 21. 38. 29. 87. 82. 68. 42. 89. 22. 55.
 42. 74.]
Iteration 1 → Master: 446.000000, Follower(seq): 653.871094, Gap: +207.871094
→ Adding new constraint from follower.
🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.09epoch/s, batch_max_reward=560, best_reward=645, loss=1.08]


🏁 Training finished
✨ Best reward: 645.1171875
🧩 Best sequence: [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]
-------------
645.1171875
645.1172
663.0
663.0
-------------
[1 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1]
[1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1.]
-------------
[3.8046875  0.         0.         0.         6.76953125 8.7421875
 9.9453125  8.8125     6.9296875  6.94921875 8.4609375  9.359375
 9.859375   8.8984375  8.03125    8.2109375  9.703125   9.359375
 8.3984375  6.28515625]
[89. 17. 91. 17. 44. 80. 82. 67. 21. 38. 29. 87. 82. 68. 42. 89. 22. 55.
 42. 74.]
Iteration 2 → Master: 663.000000, Follower(seq): 645.117188, Gap: -17.882812
🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.95epoch/s, batch_max_reward=565, best_reward=625, loss=1.09]


🏁 Training finished
✨ Best reward: 625.43359375
🧩 Best sequence: [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]
-------------
625.43359375
625.4336
663.0
663.0
-------------
[1 0 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 0 0 1]
[1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1.]
-------------
[3.8046875  0.         0.         0.         6.76953125 8.7421875
 9.9453125  8.8125     6.9296875  6.94921875 8.4609375  9.359375
 9.859375   8.8984375  8.03125    8.2109375  9.703125   9.359375
 8.3984375  6.28515625]
[89. 17. 91. 17. 44. 80. 82. 67. 21. 38. 29. 87. 82. 68. 42. 89. 22. 55.
 42. 74.]
Iteration 3 → Master: 663.000000, Follower(seq): 625.433594, Gap: -37.566406
🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.15epoch/s, batch_max_reward=591, best_reward=630, loss=1.14]


🏁 Training finished
✨ Best reward: 629.71875
🧩 Best sequence: [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]
-------------
629.71875
629.71875
663.0
663.0
-------------
[1 1 1 1 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0]
[1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1.]
-------------
[3.8046875  0.         0.         0.         6.76953125 8.7421875
 9.9453125  8.8125     6.9296875  6.94921875 8.4609375  9.359375
 9.859375   8.8984375  8.03125    8.2109375  9.703125   9.359375
 8.3984375  6.28515625]
[89. 17. 91. 17. 44. 80. 82. 67. 21. 38. 29. 87. 82. 68. 42. 89. 22. 55.
 42. 74.]
Iteration 4 → Master: 663.000000, Follower(seq): 629.718750, Gap: -33.281250
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.79epoch/s, batch_max_reward=561, best_reward=634, loss=0.975]


🏁 Training finished
✨ Best reward: 633.9375
🧩 Best sequence: [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]
-------------
633.9375
633.9375
663.0
663.0
-------------
[1 0 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1]
[1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1.]
-------------
[3.8046875  0.         0.         0.         6.76953125 8.7421875
 9.9453125  8.8125     6.9296875  6.94921875 8.4609375  9.359375
 9.859375   8.8984375  8.03125    8.2109375  9.703125   9.359375
 8.3984375  6.28515625]
[89. 17. 91. 17. 44. 80. 82. 67. 21. 38. 29. 87. 82. 68. 42. 89. 22. 55.
 42. 74.]
Iteration 5 → Master: 663.000000, Follower(seq): 633.937500, Gap: -29.062500
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.24epoch/s, batch_max_reward=621, best_reward=634, loss=0.852]


🏁 Training finished
✨ Best reward: 633.9375
🧩 Best sequence: [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]
-------------
633.9375
633.9375
663.0
663.0
-------------
[1 1 1 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1]
[1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1.]
-------------
[3.8046875  0.         0.         0.         6.76953125 8.7421875
 9.9453125  8.8125     6.9296875  6.94921875 8.4609375  9.359375
 9.859375   8.8984375  8.03125    8.2109375  9.703125   9.359375
 8.3984375  6.28515625]
[89. 17. 91. 17. 44. 80. 82. 67. 21. 38. 29. 87. 82. 68. 42. 89. 22. 55.
 42. 74.]
Iteration 6 → Master: 663.000000, Follower(seq): 633.937500, Gap: -29.062500
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.05epoch/s, batch_max_reward=566, best_reward=626, loss=0.749]


🏁 Training finished
✨ Best reward: 626.1796875
🧩 Best sequence: [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
-------------
626.1796875
626.1797
663.0
663.0
-------------
[1 0 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0]
[1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1.]
-------------
[3.8046875  0.         0.         0.         6.76953125 8.7421875
 9.9453125  8.8125     6.9296875  6.94921875 8.4609375  9.359375
 9.859375   8.8984375  8.03125    8.2109375  9.703125   9.359375
 8.3984375  6.28515625]
[89. 17. 91. 17. 44. 80. 82. 67. 21. 38. 29. 87. 82. 68. 42. 89. 22. 55.
 42. 74.]
Iteration 7 → Master: 663.000000, Follower(seq): 626.179688, Gap: -36.820312
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.41epoch/s, batch_max_reward=562, best_reward=638, loss=0.823]


🏁 Training finished
✨ Best reward: 637.8984375
🧩 Best sequence: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]
-------------
637.8984375
637.89844
663.0
663.0
-------------
[1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 0 1]
[1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1.]
-------------
[3.8046875  0.         0.         0.         6.76953125 8.7421875
 9.9453125  8.8125     6.9296875  6.94921875 8.4609375  9.359375
 9.859375   8.8984375  8.03125    8.2109375  9.703125   9.359375
 8.3984375  6.28515625]
[89. 17. 91. 17. 44. 80. 82. 67. 21. 38. 29. 87. 82. 68. 42. 89. 22. 55.
 42. 74.]
Iteration 8 → Master: 663.000000, Follower(seq): 637.898438, Gap: -25.101562
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.19epoch/s, batch_max_reward=568, best_reward=634, loss=0.743]


🏁 Training finished
✨ Best reward: 633.9375
🧩 Best sequence: [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]
-------------
633.9375
633.9375
663.0
663.0
-------------
[1 0 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1]
[1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1.]
-------------
[3.8046875  0.         0.         0.         6.76953125 8.7421875
 9.9453125  8.8125     6.9296875  6.94921875 8.4609375  9.359375
 9.859375   8.8984375  8.03125    8.2109375  9.703125   9.359375
 8.3984375  6.28515625]
[89. 17. 91. 17. 44. 80. 82. 67. 21. 38. 29. 87. 82. 68. 42. 89. 22. 55.
 42. 74.]
Iteration 9 → Master: 663.000000, Follower(seq): 633.937500, Gap: -29.062500
🚀 Starting training on device: mps for 50 epochs
Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.40epoch/s, batch_max_reward=616, best_reward=631, loss=1.2]


🏁 Training finished
✨ Best reward: 630.93359375
🧩 Best sequence: [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]
-------------
630.93359375
630.9336
663.0
663.0
-------------
[1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 0 1]
[1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1.]
-------------
[3.8046875  0.         0.         0.         6.76953125 8.7421875
 9.9453125  8.8125     6.9296875  6.94921875 8.4609375  9.359375
 9.859375   8.8984375  8.03125    8.2109375  9.703125   9.359375
 8.3984375  6.28515625]
[89. 17. 91. 17. 44. 80. 82. 67. 21. 38. 29. 87. 82. 68. 42. 89. 22. 55.
 42. 74.]
Iteration 10 → Master: 663.000000, Follower(seq): 630.933594, Gap: -32.066406
🚀 Starting training on device: mps for 50 epochs
Training:  70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                      | 35/50 [00:03<00:01,  9.45epoch/s, batch_max_reward=583, best_reward=650, loss=0.843]
Traceback (most recent call last):
  File "/Users/arthur/Library/Mobile Documents/com~apple~CloudDocs/Cours/ECN6338/Devoir à rendre/projet Avec critique/train.py", line 330, in <module>
    master_val, follower_val, iteration = solve(u_vals, t_vals, B_val, cfg)
                                          ~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/arthur/Library/Mobile Documents/com~apple~CloudDocs/Cours/ECN6338/Devoir à rendre/projet Avec critique/train.py", line 154, in solve
    follower_val_t, x_hat_sol = train_model(u_vals=u, t_vals=t_sol, B_val=B, epochs=cfg.num_epochs, batch_size=batch_size, actor=actor, critic=critic, optimizer_ac=optimizer_ac, optimizer_cr=optimizer_cr, device=device)
                                ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/arthur/Library/Mobile Documents/com~apple~CloudDocs/Cours/ECN6338/Devoir à rendre/projet Avec critique/train.py", line 244, in train_model
    loss.backward()
    ~~~~~~~~~~~~~^^
  File "/Users/arthur/miniconda3/envs/GFlowNet-Knapsack-Actor-Critic/lib/python3.13/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        self, gradient, retain_graph, create_graph, inputs=inputs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/arthur/miniconda3/envs/GFlowNet-Knapsack-Actor-Critic/lib/python3.13/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
    ~~~~~~~~~~~~~~~~~~~~^
        tensors,
        ^^^^^^^^
    ...<5 lines>...
        accumulate_grad=True,
        ^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/arthur/miniconda3/envs/GFlowNet-Knapsack-Actor-Critic/lib/python3.13/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        t_outputs, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
    )  # Calls into the C++ engine to run the backward pass
    ^
KeyboardInterrupt
