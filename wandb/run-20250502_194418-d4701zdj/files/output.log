
ðŸš€ Starting training on device: mps for 79 epochs



Training:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/79 [00:09<00:01, 10.99epoch/s, batch_max_reward=463, best_reward=516, loss=1.26]
ðŸ Training finished
âœ¨ Best reward: 516.4375
ðŸ§© Best sequence: [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]
-------------
516.4375
516.4375
275.0
275.0
-------------
[1 1 1 0 1 0 0 0 1 0 1 0 1 0 0]
[0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1.]
-------------
[0.         7.8984375  0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 1 â†’ Master: 275.000000, Follower(seq): 516.437500, Gap: +241.437500
â†’ Adding new constraint from follower.
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:10<00:00,  7.25epoch/s, batch_max_reward=456, best_reward=516, loss=1.23]


Training:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/79 [00:04<00:01, 12.96epoch/s, batch_max_reward=507, best_reward=564, loss=1.21]
ðŸ Training finished
âœ¨ Best reward: 563.89453125
ðŸ§© Best sequence: [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]
-------------
563.89453125
563.89453
563.0
563.0
-------------
[1 1 1 0 1 0 1 0 1 0 1 0 1 0 0]
[1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.]
-------------
[0.         4.28125    0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 2 â†’ Master: 563.000000, Follower(seq): 563.894531, Gap: +0.894531
â†’ Adding new constraint from follower.
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:05<00:00, 13.25epoch/s, batch_max_reward=495, best_reward=564, loss=1.3]


Training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/79 [00:04<00:01, 13.42epoch/s, batch_max_reward=538, best_reward=565, loss=1.45]
ðŸ Training finished
âœ¨ Best reward: 564.7890625
ðŸ§© Best sequence: [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]
-------------
564.7890625499999
564.78906
563.8945312999999
563.89453
-------------
[1 1 1 0 1 0 1 0 1 0 1 0 1 0 0]
[1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.]
-------------
[0.         3.3867187  0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 3 â†’ Master: 563.894531, Follower(seq): 564.789063, Gap: +0.894531
â†’ Adding new constraint from follower.
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:05<00:00, 13.26epoch/s, batch_max_reward=476, best_reward=565, loss=1.2]



Training:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/79 [00:06<00:00, 12.32epoch/s, batch_max_reward=511, best_reward=565, loss=0.98]
ðŸ Training finished
âœ¨ Best reward: 564.7890625
ðŸ§© Best sequence: [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]
-------------
564.7890625
564.78906
564.7890625
564.78906
-------------
[1 1 1 0 1 0 0 1 1 0 1 0 1 0 0]
[1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.]
-------------
[0.         2.4921875  0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 4 â†’ Master: 564.789062, Follower(seq): 564.789062, Gap: +0.000000
â†’ Convergence reached (follower == master within tolerance).

Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:07<00:00, 10.72epoch/s, batch_max_reward=539, best_reward=565, loss=1.32]