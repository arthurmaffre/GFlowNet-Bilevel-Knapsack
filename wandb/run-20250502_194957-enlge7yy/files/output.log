
🚀 Starting training on device: mps for 63 epochs


Training:  63%|██████▎   | 40/63 [00:05<00:01, 13.05epoch/s, batch_max_reward=373, best_reward=443, loss=0.266]
🏁 Training finished
✨ Best reward: 489.015625
🧩 Best sequence: [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]
-------------
489.015625
489.01562
275.0
275.0
-------------
[1 1 1 0 0 1 0 1 1 0 1 0 1 0 0]
[0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1.]
-------------
[0.         7.8984375  0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 1 → Master: 275.000000, Follower(seq): 489.015625, Gap: +214.015625
→ Adding new constraint from follower.
Training: 100%|██████████| 63/63 [00:07<00:00,  8.71epoch/s, batch_max_reward=379, best_reward=489, loss=4.51]


Training:  86%|████████▌ | 54/63 [00:04<00:00, 12.98epoch/s, batch_max_reward=568, best_reward=568, loss=0.742]
🏁 Training finished
✨ Best reward: 567.6015625
🧩 Best sequence: [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]
-------------
567.6015625
567.60156
529.0
529.0
-------------
[1 1 1 0 1 0 1 0 1 0 1 0 1 0 0]
[1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0.]
-------------
[0.         0.57421875 0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 2 → Master: 529.000000, Follower(seq): 567.601562, Gap: +38.601562
→ Adding new constraint from follower.
Training: 100%|██████████| 63/63 [00:05<00:00, 12.46epoch/s, batch_max_reward=474, best_reward=568, loss=1.22]


Training:  95%|█████████▌| 60/63 [00:04<00:00, 12.94epoch/s, batch_max_reward=504, best_reward=568, loss=0.844]Exception ignored in: <generator object tqdm.__iter__ at 0x131c74ee0>Exception ignored in sys.unraisablehook: <built-in function unraisablehook>