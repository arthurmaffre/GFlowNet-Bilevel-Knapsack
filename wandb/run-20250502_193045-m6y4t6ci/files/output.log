🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:08<00:00,  5.89epoch/s, batch_max_reward=427, best_reward=506, loss=1.15]


🏁 Training finished
✨ Best reward: 505.73046875
🧩 Best sequence: [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]
-------------
505.73046875
505.73047
275.0
275.0
-------------
[1 1 1 0 1 1 1 0 0 0 1 0 1 0 0]
[0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1.]
-------------
[0.         7.8984375  0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 1 → Master: 275.000000, Follower(seq): 505.730469, Gap: +230.730469
→ Adding new constraint from follower.
🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 12.94epoch/s, batch_max_reward=475, best_reward=565, loss=1.35]


🏁 Training finished
✨ Best reward: 564.79296875
🧩 Best sequence: [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]
-------------
564.79296875
564.79297
525.0
525.0
-------------
[1 1 1 0 1 0 1 0 1 0 1 0 1 0 0]
[1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.]
-------------
[0.         3.3828125  0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 2 → Master: 525.000000, Follower(seq): 564.792969, Gap: +39.792969
→ Adding new constraint from follower.
🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 13.17epoch/s, batch_max_reward=495, best_reward=539, loss=1.03]


🏁 Training finished
✨ Best reward: 538.51171875
🧩 Best sequence: [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]
-------------
538.5117187999999
538.5117
564.7929687999999
564.79297
-------------
[1 1 1 1 1 0 0 0 1 0 1 0 1 0 0]
[1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.]
-------------
[0.         2.4882812  0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 3 → Master: 564.792969, Follower(seq): 538.511719, Gap: -26.281250
🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 13.12epoch/s, batch_max_reward=467, best_reward=566, loss=1.32]


🏁 Training finished
✨ Best reward: 565.6875
🧩 Best sequence: [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]
-------------
565.6875000499999
565.6875
564.7929687999999
564.79297
-------------
[1 1 1 0 1 0 1 0 1 0 1 0 1 0 0]
[1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.]
-------------
[0.         2.4882812  0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 4 → Master: 564.792969, Follower(seq): 565.687500, Gap: +0.894531
→ Adding new constraint from follower.
🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 13.12epoch/s, batch_max_reward=483, best_reward=567, loss=1.13]


🏁 Training finished
✨ Best reward: 566.58203125
🧩 Best sequence: [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]
-------------
566.58203135
566.58203
565.6875001
565.6875
-------------
[1 1 1 0 1 0 1 0 1 0 1 0 1 0 0]
[1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.]
-------------
[0.         1.5937499  0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 5 → Master: 565.687500, Follower(seq): 566.582031, Gap: +0.894531
→ Adding new constraint from follower.
🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 12.27epoch/s, batch_max_reward=507, best_reward=567, loss=1.06]


🏁 Training finished
✨ Best reward: 567.4765625
🧩 Best sequence: [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]
-------------
567.4765626
567.47656
566.58203135
566.58203
-------------
[1 1 1 0 1 0 1 0 1 0 1 0 1 0 0]
[1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.]
-------------
[0.         0.69921865 0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 6 → Master: 566.582031, Follower(seq): 567.476563, Gap: +0.894531
→ Adding new constraint from follower.
🚀 Starting training on device: mps for 50 epochs
Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 13.05epoch/s, batch_max_reward=463, best_reward=542, loss=1.3]


🏁 Training finished
✨ Best reward: 542.44140625
🧩 Best sequence: [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]
-------------
542.44140635
542.4414
567.4765626
567.47656
-------------
[1 1 1 0 1 0 0 0 1 0 1 0 1 1 0]
[1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0.]
-------------
[0.         0.69921865 0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 7 → Master: 567.476563, Follower(seq): 542.441406, Gap: -25.035156
🚀 Starting training on device: mps for 50 epochs
Training:  78%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                               | 39/50 [00:03<00:00, 12.61epoch/s, batch_max_reward=499, best_reward=537, loss=4.25]
Traceback (most recent call last):
  File "/Users/arthur/Library/Mobile Documents/com~apple~CloudDocs/Cours/ECN6338/Devoir à rendre/projet Avec critique/train.py", line 349, in <module>
    master_val, follower_val, iteration = solve(u_vals, t_vals, B_val, cfg)
                                          ~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/arthur/Library/Mobile Documents/com~apple~CloudDocs/Cours/ECN6338/Devoir à rendre/projet Avec critique/train.py", line 155, in solve
    follower_val_t, x_hat_sol = train_model(u_vals=u, t_vals=t_sol, B_val=B, epochs=cfg.num_epochs, batch_size=batch_size, actor=actor, critic=critic, optimizer_ac=optimizer_ac, optimizer_cr=optimizer_cr, device=device)
                                ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/arthur/Library/Mobile Documents/com~apple~CloudDocs/Cours/ECN6338/Devoir à rendre/projet Avec critique/train.py", line 263, in train_model
    loss.backward()
    ~~~~~~~~~~~~~^^
  File "/Users/arthur/miniconda3/envs/GFlowNet-Knapsack-Actor-Critic/lib/python3.13/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        self, gradient, retain_graph, create_graph, inputs=inputs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/arthur/miniconda3/envs/GFlowNet-Knapsack-Actor-Critic/lib/python3.13/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
    ~~~~~~~~~~~~~~~~~~~~^
        tensors,
        ^^^^^^^^
    ...<5 lines>...
        accumulate_grad=True,
        ^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/arthur/miniconda3/envs/GFlowNet-Knapsack-Actor-Critic/lib/python3.13/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        t_outputs, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
    )  # Calls into the C++ engine to run the backward pass
    ^
KeyboardInterrupt
