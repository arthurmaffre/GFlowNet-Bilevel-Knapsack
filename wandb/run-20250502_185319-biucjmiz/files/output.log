🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  7.62epoch/s, batch_max_reward=656, best_reward=740, loss=0.854]


🏁 Training finished
✨ Best reward: 740.4296875
🧩 Best sequence: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
-------------
740.4296875499999
740.4297
480.00000005
480.0
-------------
[1 1 1 1 0 0 1 1 1 1 0 0 1 1 0 0 0 1 1 0 1 0 0 0 0]
[0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0.
 0.]
-------------
[0.         0.         0.         9.4492187  0.         7.14453125
 7.32421875 7.71484375 6.65234375 9.2421875  8.1015625  8.890625
 8.109375   6.77734375 6.40625    7.38671875 6.34765625 8.15625
 6.18359375 8.9296875  9.9609375  8.8203125  7.3125     9.984375
 8.953125  ]
[96. 14. 59. 83. 23. 39. 53. 34. 48. 26. 14. 32. 99. 78. 41. 39. 32. 72.
 80. 14. 78. 63. 19. 25. 46.]
Iteration 1 → Master: 480.000000, Follower(seq): 740.429688, Gap: +260.429687
→ Adding new constraint from follower.
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.46epoch/s, batch_max_reward=742, best_reward=792, loss=0.874]


🏁 Training finished
✨ Best reward: 792.37890625
🧩 Best sequence: [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]
-------------
792.37890625
792.3789
792.0
792.0
-------------
[1 1 1 1 0 1 0 1 0 0 0 0 1 1 1 0 1 1 1 0 1 1 0 0 0]
[1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0.
 0.]
-------------
[0.         0.         0.         0.         4.         7.14453125
 7.32421875 7.71484375 6.65234375 9.2421875  8.1015625  8.890625
 8.109375   6.77734375 6.40625    7.38671875 6.34765625 8.15625
 6.18359375 8.9296875  9.9609375  8.8203125  7.3125     9.984375
 8.953125  ]
[96. 14. 59. 83. 23. 39. 53. 34. 48. 26. 14. 32. 99. 78. 41. 39. 32. 72.
 80. 14. 78. 63. 19. 25. 46.]
Iteration 2 → Master: 792.000000, Follower(seq): 792.378906, Gap: +0.378906
→ Adding new constraint from follower.
🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  8.18epoch/s, batch_max_reward=690, best_reward=775, loss=1.01]


🏁 Training finished
✨ Best reward: 775.0234375
🧩 Best sequence: [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
-------------
775.0234375
775.02344
798.0
798.0
-------------
[1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 0]
[1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0.
 0.]
-------------
[0.         0.         0.         0.         4.3515625  7.14453125
 7.32421875 7.71484375 6.65234375 9.2421875  8.1015625  8.890625
 8.109375   6.77734375 6.40625    7.38671875 6.34765625 8.15625
 6.18359375 8.9296875  9.9609375  8.8203125  7.3125     9.984375
 8.953125  ]
[96. 14. 59. 83. 23. 39. 53. 34. 48. 26. 14. 32. 99. 78. 41. 39. 32. 72.
 80. 14. 78. 63. 19. 25. 46.]
Iteration 3 → Master: 798.000000, Follower(seq): 775.023438, Gap: -22.976562
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  8.24epoch/s, batch_max_reward=720, best_reward=774, loss=0.694]


🏁 Training finished
✨ Best reward: 774.17578125
🧩 Best sequence: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]
-------------
774.17578125
774.1758
798.0
798.0
-------------
[1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 0]
[1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0.
 0.]
-------------
[0.         0.         0.         0.         4.3515625  7.14453125
 7.32421875 7.71484375 6.65234375 9.2421875  8.1015625  8.890625
 8.109375   6.77734375 6.40625    7.38671875 6.34765625 8.15625
 6.18359375 8.9296875  9.9609375  8.8203125  7.3125     9.984375
 8.953125  ]
[96. 14. 59. 83. 23. 39. 53. 34. 48. 26. 14. 32. 99. 78. 41. 39. 32. 72.
 80. 14. 78. 63. 19. 25. 46.]
Iteration 4 → Master: 798.000000, Follower(seq): 774.175781, Gap: -23.824219
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  8.30epoch/s, batch_max_reward=713, best_reward=802, loss=0.989]


🏁 Training finished
✨ Best reward: 802.28125
🧩 Best sequence: [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
-------------
802.28125
802.28125
798.0
798.0
-------------
[1 1 1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1 0 1 0 0 0 0]
[1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0.
 0.]
-------------
[0.         0.         0.         0.         4.3515625  7.14453125
 7.32421875 7.71484375 6.65234375 9.2421875  8.1015625  8.890625
 8.109375   6.77734375 6.40625    7.38671875 6.34765625 8.15625
 6.18359375 8.9296875  9.9609375  8.8203125  7.3125     9.984375
 8.953125  ]
[96. 14. 59. 83. 23. 39. 53. 34. 48. 26. 14. 32. 99. 78. 41. 39. 32. 72.
 80. 14. 78. 63. 19. 25. 46.]
Iteration 5 → Master: 798.000000, Follower(seq): 802.281250, Gap: +4.281250
→ Adding new constraint from follower.
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  8.25epoch/s, batch_max_reward=663, best_reward=754, loss=0.887]


🏁 Training finished
✨ Best reward: 754.41015625
🧩 Best sequence: [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
-------------
754.41015625
754.41016
844.0000000499999
844.0
-------------
[1 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0]
[1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0.
 0.]
-------------
[0.         0.         0.         0.         6.4648437  7.14453125
 7.32421875 7.71484375 6.65234375 9.2421875  8.1015625  8.890625
 8.109375   6.77734375 6.40625    7.38671875 6.34765625 8.15625
 6.18359375 8.9296875  9.9609375  8.8203125  7.3125     9.984375
 8.953125  ]
[96. 14. 59. 83. 23. 39. 53. 34. 48. 26. 14. 32. 99. 78. 41. 39. 32. 72.
 80. 14. 78. 63. 19. 25. 46.]
Iteration 6 → Master: 844.000000, Follower(seq): 754.410156, Gap: -89.589844
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.51epoch/s, batch_max_reward=728, best_reward=764, loss=0.977]


🏁 Training finished
✨ Best reward: 763.6484375
🧩 Best sequence: [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]
-------------
763.6484375499999
763.64844
844.0000000499999
844.0
-------------
[1 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0 1 1 0 1 0]
[1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0.
 0.]
-------------
[0.         0.         0.         0.         6.4648437  7.14453125
 7.32421875 7.71484375 6.65234375 9.2421875  8.1015625  8.890625
 8.109375   6.77734375 6.40625    7.38671875 6.34765625 8.15625
 6.18359375 8.9296875  9.9609375  8.8203125  7.3125     9.984375
 8.953125  ]
[96. 14. 59. 83. 23. 39. 53. 34. 48. 26. 14. 32. 99. 78. 41. 39. 32. 72.
 80. 14. 78. 63. 19. 25. 46.]
Iteration 7 → Master: 844.000000, Follower(seq): 763.648438, Gap: -80.351562
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.56epoch/s, batch_max_reward=697, best_reward=763, loss=0.733]


🏁 Training finished
✨ Best reward: 763.3125
🧩 Best sequence: [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
-------------
763.3125
763.3125
844.0000000499999
844.0
-------------
[1 0 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 0 0 0 0 0]
[1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0.
 0.]
-------------
[0.         0.         0.         0.         6.4648437  7.14453125
 7.32421875 7.71484375 6.65234375 9.2421875  8.1015625  8.890625
 8.109375   6.77734375 6.40625    7.38671875 6.34765625 8.15625
 6.18359375 8.9296875  9.9609375  8.8203125  7.3125     9.984375
 8.953125  ]
[96. 14. 59. 83. 23. 39. 53. 34. 48. 26. 14. 32. 99. 78. 41. 39. 32. 72.
 80. 14. 78. 63. 19. 25. 46.]
Iteration 8 → Master: 844.000000, Follower(seq): 763.312500, Gap: -80.687500
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  8.29epoch/s, batch_max_reward=740, best_reward=779, loss=0.822]


🏁 Training finished
✨ Best reward: 779.4609375
🧩 Best sequence: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]
-------------
779.4609375
779.46094
844.0000000499999
844.0
-------------
[1 1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 0]
[1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0.
 0.]
-------------
[0.         0.         0.         0.         6.4648437  7.14453125
 7.32421875 7.71484375 6.65234375 9.2421875  8.1015625  8.890625
 8.109375   6.77734375 6.40625    7.38671875 6.34765625 8.15625
 6.18359375 8.9296875  9.9609375  8.8203125  7.3125     9.984375
 8.953125  ]
[96. 14. 59. 83. 23. 39. 53. 34. 48. 26. 14. 32. 99. 78. 41. 39. 32. 72.
 80. 14. 78. 63. 19. 25. 46.]
Iteration 9 → Master: 844.000000, Follower(seq): 779.460938, Gap: -64.539063
🚀 Starting training on device: mps for 50 epochs
Training:   8%|███████████████████████                                                                                                                                                                                                                                                                         | 4/50 [00:00<00:06,  6.67epoch/s, batch_max_reward=687, best_reward=786, loss=0.907]
Traceback (most recent call last):
  File "/Users/arthur/Library/Mobile Documents/com~apple~CloudDocs/Cours/ECN6338/Devoir à rendre/projet Avec critique/train.py", line 330, in <module>
    master_val, follower_val, iteration = solve(u_vals, t_vals, B_val, cfg)
                                          ~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/arthur/Library/Mobile Documents/com~apple~CloudDocs/Cours/ECN6338/Devoir à rendre/projet Avec critique/train.py", line 154, in solve
    follower_val_t, x_hat_sol = train_model(u_vals=u, t_vals=t_sol, B_val=B, epochs=cfg.num_epochs, batch_size=batch_size, actor=actor, critic=critic, optimizer_ac=optimizer_ac, optimizer_cr=optimizer_cr, device=device)
                                ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/arthur/Library/Mobile Documents/com~apple~CloudDocs/Cours/ECN6338/Devoir à rendre/projet Avec critique/train.py", line 244, in train_model
    loss.backward()
    ~~~~~~~~~~~~~^^
  File "/Users/arthur/miniconda3/envs/GFlowNet-Knapsack-Actor-Critic/lib/python3.13/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        self, gradient, retain_graph, create_graph, inputs=inputs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/arthur/miniconda3/envs/GFlowNet-Knapsack-Actor-Critic/lib/python3.13/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
    ~~~~~~~~~~~~~~~~~~~~^
        tensors,
        ^^^^^^^^
    ...<5 lines>...
        accumulate_grad=True,
        ^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/arthur/miniconda3/envs/GFlowNet-Knapsack-Actor-Critic/lib/python3.13/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        t_outputs, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
    )  # Calls into the C++ engine to run the backward pass
    ^
KeyboardInterrupt
