
🚀 Starting training on device: mps for 46 epochs






Training:  78%|███████▊  | 36/46 [00:17<00:02,  4.12epoch/s, batch_max_reward=490, best_reward=516, loss=1.26]
🏁 Training finished
✨ Best reward: 516.4375
🧩 Best sequence: [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]
-------------
516.4375
516.4375
275.0
275.0
-------------
[1 1 1 0 1 0 0 0 1 0 1 0 1 0 0]
[0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1.]
-------------
[0.         7.8984375  0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 1 → Master: 275.000000, Follower(seq): 516.437500, Gap: +241.437500
Training: 100%|██████████| 46/46 [00:19<00:00,  2.35epoch/s, batch_max_reward=471, best_reward=516, loss=1.67]
Training:   0%|          | 0/46 [00:00<?, ?epoch/s]






Training:  98%|█████████▊| 45/46 [00:12<00:00,  2.20epoch/s, batch_max_reward=530, best_reward=563, loss=1.55]
🏁 Training finished
✨ Best reward: 563.0
🧩 Best sequence: [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]
-------------
563.0
563.0
563.0
563.0
-------------
[1 1 1 0 1 0 0 1 1 0 1 0 1 0 0]
[1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.]
-------------
[0.         4.28125    0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 2 → Master: 563.000000, Follower(seq): 563.000000, Gap: +0.000000
→ Convergence reached (follower == master within tolerance).

Training: 100%|██████████| 46/46 [00:12<00:00,  3.66epoch/s, batch_max_reward=474, best_reward=563, loss=0.898]