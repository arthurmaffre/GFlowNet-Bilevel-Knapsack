🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.79epoch/s, batch_max_reward=534, best_reward=576, loss=1.65]


🏁 Training finished
✨ Best reward: 576.5
🧩 Best sequence: [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]
-------------
576.5
576.5
372.99999995
373.0
-------------
[0 1 1 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 1]
[1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0.]
-------------
[8.9101563  0.         0.         0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 1 → Master: 373.000000, Follower(seq): 576.500000, Follower(analytic): 616.468750, Gap: +203.500000
→ Adding new constraint from follower.
🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.38epoch/s, batch_max_reward=543, best_reward=615, loss=1.07]


🏁 Training finished
✨ Best reward: 615.453125
🧩 Best sequence: [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
-------------
615.453125
615.4531
584.0
584.0
-------------
[1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 1 0]
[1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0.]
-------------
[0.         2.09375    0.         0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 2 → Master: 584.000000, Follower(seq): 615.453125, Follower(analytic): 669.375000, Gap: +31.453125
→ Adding new constraint from follower.
🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.79epoch/s, batch_max_reward=508, best_reward=583, loss=1.06]


🏁 Training finished
✨ Best reward: 583.15234375
🧩 Best sequence: [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
-------------
583.15234375
583.15234
616.0
616.0
-------------
[1 1 0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 0 0 0]
[1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.]
-------------
[0.         3.15625    0.         0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 3 → Master: 616.000000, Follower(seq): 583.152344, Follower(analytic): 668.312500, Gap: -32.847656
🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.86epoch/s, batch_max_reward=526, best_reward=646, loss=1.03]


🏁 Training finished
✨ Best reward: 645.60546875
🧩 Best sequence: [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]
-------------
645.60546875
645.60547
616.0
616.0
-------------
[1 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0]
[1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.]
-------------
[0.         3.15625    0.         0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 4 → Master: 616.000000, Follower(seq): 645.605469, Follower(analytic): 668.312500, Gap: +29.605469
→ Adding new constraint from follower.
🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.50epoch/s, batch_max_reward=533, best_reward=624, loss=1.01]


🏁 Training finished
✨ Best reward: 623.52734375
🧩 Best sequence: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]
-------------
623.5273437000001
623.52734
651.9999999500001
652.0
-------------
[1 1 1 1 0 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0]
[1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.]
-------------
[0.         0.         3.3242188  0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 5 → Master: 652.000000, Follower(seq): 623.527344, Follower(analytic): 668.144531, Gap: -28.472656
🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.88epoch/s, batch_max_reward=503, best_reward=608, loss=1.09]


🏁 Training finished
✨ Best reward: 608.1171875
🧩 Best sequence: [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
-------------
608.1171874500001
608.1172
651.9999999500001
652.0
-------------
[1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0]
[1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.]
-------------
[0.         0.         3.3242188  0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 6 → Master: 652.000000, Follower(seq): 608.117187, Follower(analytic): 668.144531, Gap: -43.882812
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.90epoch/s, batch_max_reward=557, best_reward=573, loss=0.846]


🏁 Training finished
✨ Best reward: 573.08984375
🧩 Best sequence: [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
-------------
573.0898437000001
573.08984
651.9999999500001
652.0
-------------
[1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0]
[1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.]
-------------
[0.         0.         3.3242188  0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 7 → Master: 652.000000, Follower(seq): 573.089844, Follower(analytic): 668.144531, Gap: -78.910156
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00, 10.00epoch/s, batch_max_reward=527, best_reward=668, loss=0.998]


🏁 Training finished
✨ Best reward: 668.14453125
🧩 Best sequence: [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]
-------------
668.1445312000001
668.14453
651.9999999500001
652.0
-------------
[1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0]
[1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.]
-------------
[0.         0.         3.3242188  0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 8 → Master: 652.000000, Follower(seq): 668.144531, Follower(analytic): 668.144531, Gap: +16.144531
→ Adding new constraint from follower.
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.94epoch/s, batch_max_reward=526, best_reward=616, loss=0.805]


🏁 Training finished
✨ Best reward: 616.46875
🧩 Best sequence: [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]
-------------
616.46875
616.46875
668.1445312000001
668.14453
-------------
[0 1 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0]
[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]
-------------
[3.3242188  0.         0.         0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 9 → Master: 668.144531, Follower(seq): 616.468750, Follower(analytic): 668.144531, Gap: -51.675781
🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.06epoch/s, batch_max_reward=518, best_reward=584, loss=1.08]


🏁 Training finished
✨ Best reward: 584.02734375
🧩 Best sequence: [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
-------------
584.02734375
584.02734
668.1445312000001
668.14453
-------------
[0 1 1 1 0 1 1 1 1 1 0 1 0 0 0 1 0 0 0 0]
[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]
-------------
[3.3242188  0.         0.         0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 10 → Master: 668.144531, Follower(seq): 584.027344, Follower(analytic): 668.144531, Gap: -84.117187
🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.04epoch/s, batch_max_reward=587, best_reward=590, loss=1.23]


🏁 Training finished
✨ Best reward: 590.390625
🧩 Best sequence: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]
-------------
590.3906249500001
590.3906
668.1445312000001
668.14453
-------------
[1 1 1 1 0 0 0 1 1 1 0 0 1 0 0 1 1 0 1 0]
[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]
-------------
[3.3242188  0.         0.         0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 11 → Master: 668.144531, Follower(seq): 590.390625, Follower(analytic): 668.144531, Gap: -77.753906
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.18epoch/s, batch_max_reward=507, best_reward=591, loss=0.911]


🏁 Training finished
✨ Best reward: 590.52734375
🧩 Best sequence: [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]
-------------
590.5273437000001
590.52734
668.1445312000001
668.14453
-------------
[1 1 1 0 0 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0]
[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]
-------------
[3.3242188  0.         0.         0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 12 → Master: 668.144531, Follower(seq): 590.527344, Follower(analytic): 668.144531, Gap: -77.617188
🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.11epoch/s, batch_max_reward=535, best_reward=592, loss=1.02]


🏁 Training finished
✨ Best reward: 592.14453125
🧩 Best sequence: [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]
-------------
592.1445312000001
592.14453
668.1445312000001
668.14453
-------------
[1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0]
[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]
-------------
[3.3242188  0.         0.         0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 13 → Master: 668.144531, Follower(seq): 592.144531, Follower(analytic): 668.144531, Gap: -76.000000
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.89epoch/s, batch_max_reward=509, best_reward=632, loss=0.826]


🏁 Training finished
✨ Best reward: 632.0
🧩 Best sequence: [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]
-------------
631.9999999500001
632.0
668.1445312000001
668.14453
-------------
[1 1 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0]
[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]
-------------
[3.3242188  0.         0.         0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 14 → Master: 668.144531, Follower(seq): 632.000000, Follower(analytic): 668.144531, Gap: -36.144531
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.21epoch/s, batch_max_reward=547, best_reward=596, loss=0.996]


🏁 Training finished
✨ Best reward: 596.375
🧩 Best sequence: [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]
-------------
596.3749999500001
596.375
668.1445312000001
668.14453
-------------
[1 0 1 1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 1]
[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]
-------------
[3.3242188  0.         0.         0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 15 → Master: 668.144531, Follower(seq): 596.375000, Follower(analytic): 668.144531, Gap: -71.769531
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.21epoch/s, batch_max_reward=545, best_reward=623, loss=0.992]


🏁 Training finished
✨ Best reward: 622.703125
🧩 Best sequence: [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
-------------
622.7031249500001
622.7031
668.1445312000001
668.14453
-------------
[1 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 0 0 0 0]
[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]
-------------
[3.3242188  0.         0.         0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 16 → Master: 668.144531, Follower(seq): 622.703125, Follower(analytic): 668.144531, Gap: -45.441406
🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.17epoch/s, batch_max_reward=497, best_reward=603, loss=1.06]


🏁 Training finished
✨ Best reward: 602.703125
🧩 Best sequence: [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
-------------
602.7031249500001
602.7031
668.1445312000001
668.14453
-------------
[1 1 1 0 0 1 1 1 1 1 0 1 0 0 0 1 0 0 0 0]
[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]
-------------
[3.3242188  0.         0.         0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 17 → Master: 668.144531, Follower(seq): 602.703125, Follower(analytic): 668.144531, Gap: -65.441406
🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.20epoch/s, batch_max_reward=527, best_reward=610, loss=0.76]


🏁 Training finished
✨ Best reward: 610.19140625
🧩 Best sequence: [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]
-------------
610.1914062000001
610.1914
668.1445312000001
668.14453
-------------
[1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0]
[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]
-------------
[3.3242188  0.         0.         0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 18 → Master: 668.144531, Follower(seq): 610.191406, Follower(analytic): 668.144531, Gap: -57.953125
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.13epoch/s, batch_max_reward=556, best_reward=596, loss=0.879]


🏁 Training finished
✨ Best reward: 595.8046875
🧩 Best sequence: [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]
-------------
595.8046874500001
595.8047
668.1445312000001
668.14453
-------------
[1 0 1 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0]
[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]
-------------
[3.3242188  0.         0.         0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 19 → Master: 668.144531, Follower(seq): 595.804687, Follower(analytic): 668.144531, Gap: -72.339844
🚀 Starting training on device: mps for 50 epochs
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.63epoch/s, batch_max_reward=505, best_reward=581, loss=0.86]


🏁 Training finished
✨ Best reward: 580.796875
🧩 Best sequence: [0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]
-------------
580.796875
580.7969
668.1445312000001
668.14453
-------------
[0 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0]
[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]
-------------
[3.3242188  0.         0.         0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 20 → Master: 668.144531, Follower(seq): 580.796875, Follower(analytic): 668.144531, Gap: -87.347656
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.59epoch/s, batch_max_reward=515, best_reward=665, loss=0.732]


🏁 Training finished
✨ Best reward: 665.0
🧩 Best sequence: [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]
-------------
664.9999999500001
665.0
668.1445312000001
668.14453
-------------
[1 1 1 1 0 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0]
[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]
-------------
[3.3242188  0.         0.         0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 21 → Master: 668.144531, Follower(seq): 665.000000, Follower(analytic): 668.144531, Gap: -3.144531
🚀 Starting training on device: mps for 50 epochs
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.56epoch/s, batch_max_reward=560, best_reward=600, loss=0.978]


🏁 Training finished
✨ Best reward: 600.3828125
🧩 Best sequence: [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]
-------------
600.3828124500001
600.3828
668.1445312000001
668.14453
-------------
[1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 0 1 0]
[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]
-------------
[3.3242188  0.         0.         0.         9.9609375  9.4375
 7.046875   7.32421875 6.23828125 6.87890625 9.         7.19140625
 7.91015625 7.46875    8.265625   6.85546875 8.328125   9.53125
 7.75       7.34375   ]
[55. 13. 43. 33. 23. 96. 65. 80. 74. 81. 19. 62. 53. 26. 23. 88. 30. 17.
 95. 48.]
Iteration 22 → Master: 668.144531, Follower(seq): 600.382812, Follower(analytic): 668.144531, Gap: -67.761719
🚀 Starting training on device: mps for 50 epochs
Training:  34%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                             | 17/50 [00:01<00:03,  9.60epoch/s, batch_max_reward=513, best_reward=618, loss=0.982]
Traceback (most recent call last):
  File "/Users/arthur/Library/Mobile Documents/com~apple~CloudDocs/Cours/ECN6338/Devoir à rendre/projet Avec critique/train.py", line 330, in <module>
    master_val, follower_val, iteration = solve(u_vals, t_vals, B_val, cfg)
                                          ~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/arthur/Library/Mobile Documents/com~apple~CloudDocs/Cours/ECN6338/Devoir à rendre/projet Avec critique/train.py", line 154, in solve
    follower_val_t, x_hat_sol = train_model(u_vals=u, t_vals=t_sol, B_val=B, epochs=cfg.num_epochs, batch_size=batch_size, actor=actor, critic=critic, optimizer_ac=optimizer_ac, optimizer_cr=optimizer_cr, device=device)
                                ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/arthur/Library/Mobile Documents/com~apple~CloudDocs/Cours/ECN6338/Devoir à rendre/projet Avec critique/train.py", line 244, in train_model
    loss.backward()
    ~~~~~~~~~~~~~^^
  File "/Users/arthur/miniconda3/envs/GFlowNet-Knapsack-Actor-Critic/lib/python3.13/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        self, gradient, retain_graph, create_graph, inputs=inputs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/arthur/miniconda3/envs/GFlowNet-Knapsack-Actor-Critic/lib/python3.13/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
    ~~~~~~~~~~~~~~~~~~~~^
        tensors,
        ^^^^^^^^
    ...<5 lines>...
        accumulate_grad=True,
        ^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/arthur/miniconda3/envs/GFlowNet-Knapsack-Actor-Critic/lib/python3.13/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        t_outputs, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
    )  # Calls into the C++ engine to run the backward pass
    ^
KeyboardInterrupt
