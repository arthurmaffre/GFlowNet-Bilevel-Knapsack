
ðŸš€ Starting training on device: mps for 63 epochs


Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 38/63 [00:07<00:01, 13.36epoch/s, batch_max_reward=373, best_reward=373, loss=nan]
ðŸ Training finished
âœ¨ Best reward: 373.15234375
ðŸ§© Best sequence: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
-------------
373.15234375
373.15234
275.0
275.0
-------------
[1 1 1 1 1 1 1 0 0 0 0 0 0 1 0]
[0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1.]
-------------
[0.         7.8984375  0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 1 â†’ Master: 275.000000, Follower(seq): 373.152344, Gap: +98.152344
â†’ Adding new constraint from follower.
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:09<00:00,  6.74epoch/s, batch_max_reward=373, best_reward=373, loss=nan]


Training:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 56/63 [00:04<00:00, 13.67epoch/s, batch_max_reward=400, best_reward=400, loss=nan]
ðŸ Training finished
âœ¨ Best reward: 399.96484375
ðŸ§© Best sequence: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
-------------
399.96484375
399.96484
386.0
386.0
-------------
[1 1 1 1 1 1 1 1 0 0 0 0 0 0 0]
[0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1.]
-------------
[0.         5.2265625  0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 2 â†’ Master: 386.000000, Follower(seq): 399.964844, Gap: +13.964844
â†’ Adding new constraint from follower.
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:04<00:00, 13.18epoch/s, batch_max_reward=400, best_reward=400, loss=nan]

Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 42/63 [00:03<00:01, 12.32epoch/s, batch_max_reward=353, best_reward=353, loss=nan]
ðŸ Training finished
âœ¨ Best reward: 353.40234375
ðŸ§© Best sequence: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
-------------
353.40234375
353.40234
419.0
419.0
-------------
[1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]
[1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1.]
-------------
[0.         8.84375    0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 3 â†’ Master: 419.000000, Follower(seq): 353.402344, Gap: -65.597656
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:05<00:00, 11.98epoch/s, batch_max_reward=353, best_reward=353, loss=nan]


Training:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/63 [00:04<00:01, 10.84epoch/s, batch_max_reward=353, best_reward=353, loss=nan]
ðŸ Training finished
âœ¨ Best reward: 353.40234375
ðŸ§© Best sequence: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
-------------
353.40234375
353.40234
419.0
419.0
-------------
[1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]
[1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1.]
-------------
[0.         8.84375    0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 4 â†’ Master: 419.000000, Follower(seq): 353.402344, Gap: -65.597656
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:05<00:00, 11.79epoch/s, batch_max_reward=353, best_reward=353, loss=nan]


Training:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 54/63 [00:04<00:00, 13.08epoch/s, batch_max_reward=353, best_reward=353, loss=nan]
ðŸ Training finished
âœ¨ Best reward: 353.40234375
ðŸ§© Best sequence: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
-------------
353.40234375
353.40234
419.0
419.0
-------------
[1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]
[1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1.]
-------------
[0.         8.84375    0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 5 â†’ Master: 419.000000, Follower(seq): 353.402344, Gap: -65.597656
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:05<00:00, 11.44epoch/s, batch_max_reward=353, best_reward=353, loss=nan]

Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 46/63 [00:03<00:01, 13.83epoch/s, batch_max_reward=353, best_reward=353, loss=nan]
ðŸ Training finished
âœ¨ Best reward: 353.40234375
ðŸ§© Best sequence: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
-------------
353.40234375
353.40234
419.0
419.0
-------------
[1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]
[1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1.]
-------------
[0.         8.84375    0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 6 â†’ Master: 419.000000, Follower(seq): 353.402344, Gap: -65.597656
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:04<00:00, 13.71epoch/s, batch_max_reward=353, best_reward=353, loss=nan]

Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 38/63 [00:02<00:01, 13.66epoch/s, batch_max_reward=353, best_reward=353, loss=nan]
ðŸ Training finished
âœ¨ Best reward: 353.40234375
ðŸ§© Best sequence: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
-------------
353.40234375
353.40234
419.0
419.0
-------------
[1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]
[1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1.]
-------------
[0.         8.84375    0.         8.3359375  9.9453125  6.3125
 7.16015625 8.0546875  9.765625   7.921875   6.9765625  8.7421875
 6.9765625  6.1953125  8.953125  ]
[74. 93. 27. 25. 99. 25. 51. 51. 83. 18. 88. 10. 94. 25. 40.]
Iteration 7 â†’ Master: 419.000000, Follower(seq): 353.402344, Gap: -65.597656

Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:04<00:00, 13.57epoch/s, batch_max_reward=353, best_reward=353, loss=nan]